{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ba12624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"]= os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\", \"true\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\", \"https://api.langsmith.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cc319",
   "metadata": {},
   "source": [
    "### This step is Optional Just to show the LLM is working by making Groq Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "965484af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'} template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'\n",
      "Question: What is the capital of France?\n",
      "Thought: The capital city of France is well‑known and commonly referenced.\n",
      "Final Answer: Paris.\n"
     ]
    }
   ],
   "source": [
    "## Install necessary packages and import modules\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "from langchain_classic.agents.react.agent import create_react_agent\n",
    "from langchain_classic import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "\n",
    "# Pull the react prompt from LangChain hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# Create the agent (with empty tools list)\n",
    "agent = prompt | llm | StrOutputParser()\n",
    "\n",
    "result = agent.invoke( {\"input\":\"What is the capital of France?\",\n",
    "                        \"tools\": [],\"agent_scratchpad\": \"\",\"tool_names\": []})\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7d002",
   "metadata": {},
   "source": [
    "## Buidling Retrievers for RAG to optimize the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8ddcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Example usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "\n",
    "sources = {\n",
    "        \"anti_patterns\": \"playbook/SQL_anti_pattern.pdf\",\n",
    "        \"databricks\": \"playbook/Optimize_Databricks_Queries_overcast.pdf\",\n",
    "        \"spark\": \"playbook/spark_perf_tunning.pdf\"\n",
    "    }\n",
    "\n",
    "split_documents_list = []\n",
    "for source_name, pdf_path in sources.items():\n",
    "    # Example usage of PyPDFLoader\n",
    "    pdf_loader = PyPDFLoader(pdf_path)  # Replace with actual PDF path\n",
    "    pdf_documents = pdf_loader.load()\n",
    "    for d in pdf_documents:\n",
    "        d.metadata[\"source\"] = source_name\n",
    "\n",
    "    doc_splits = text_splitter.split_documents(pdf_documents)\n",
    "    split_documents_list.extend(doc_splits)\n",
    "    embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    Chroma.from_documents(\n",
    "            doc_splits,\n",
    "            embd,\n",
    "            persist_directory=f\"./chroma/{source_name}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5633be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JSON documents loaded: 2\n",
      "Number of documents in vectorstore: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Example usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
    "\n",
    "\n",
    "# Example usage of JSONLoader\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"stats/table_stats.json\",\n",
    "    jq_schema=\".[]\",\n",
    "    text_content=False)  # Replace with actual JSON path\n",
    "json_documents = json_loader.load()\n",
    "\n",
    "# Convert to new Documents with descriptive text\n",
    "new_documents = []\n",
    "for doc in json_documents:\n",
    "    data = json.loads(doc.page_content)\n",
    "    # Assuming JSON has keys: table_name, rows, partitioned_by\n",
    "    page_content = f\"Table {data.get('table', 'unknown')} has {data.get('row_count', 'unknown')} rows, partitioned by {data.get('partition_cols', 'unknown')} and size {data.get('size_mb', 'unknown')} mb.\"\n",
    "    metadata = {\"category\": \"table_stats\"}\n",
    "    new_doc = Document(page_content=page_content, metadata=metadata)\n",
    "    new_documents.append(new_doc)\n",
    "\n",
    "print(f\"Number of JSON documents loaded: {len(new_documents)}\")\n",
    "doc_splits = text_splitter.split_documents(new_documents)\n",
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# Add to vectorstore\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embd\n",
    ")\n",
    "\n",
    "print(f\"Number of documents in vectorstore: {vectorstore.index.ntotal}\")\n",
    "table_stats_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Example retrieval\n",
    "#query = \"provide table names ?\"\n",
    "#results = table_stats_retriever.invoke(query, k=2)\n",
    "#for i, doc in enumerate(results):\n",
    "#    print(f\"\\nDocument {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57b75fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def load_retriever(name):\n",
    "    embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    db = Chroma(\n",
    "        persist_directory=f\"./chroma/{name}\",\n",
    "        embedding_function=embd\n",
    "    )\n",
    "    return db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Example usage\n",
    "#retriever = load_retriever(\"anti_patterns\")\n",
    "#retriever.invoke(\"What is select * anti-patterns?\")\n",
    "#!/usr/bin/env python3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112818b",
   "metadata": {},
   "source": [
    "## Tools and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18ecfb",
   "metadata": {},
   "source": [
    "### Defining Langraph State\n",
    "#### Using the Pydantic as the state class for the implicit validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f30e4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Core Input ----------\n",
    "# This will be captured from system.query_history of Databricks\n",
    "class QueryMetadata(BaseModel):\n",
    "    user_name: str\n",
    "    statement_text: str\n",
    "    status: str\n",
    "    start_time: datetime\n",
    "    end_time: datetime\n",
    "    warehouse_id: Optional[str] = None\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- RAG Document ----------\n",
    "\n",
    "class RagDocument(BaseModel):\n",
    "    content: str\n",
    "    source: str\n",
    "    score: Optional[float] = None\n",
    "\n",
    "\n",
    "# ---------- Slowness Scoring ----------\n",
    "\n",
    "class SlownessScore(BaseModel):\n",
    "    duration_seconds: float\n",
    "    normalized_score: float = Field(\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"0 = fast, 1 = very slow\"\n",
    "    )\n",
    "    reason: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- Optimization Output ----------\n",
    "\n",
    "class OptimizationResult(BaseModel):\n",
    "    needs_optimization: bool\n",
    "    result: Optional[str] = None\n",
    "    optimized_query: Optional[str] = None\n",
    "    suggestions: List[str]\n",
    "    applied_rules: List[str]\n",
    "\n",
    "\n",
    "# ---------- Self Evaluation ----------\n",
    "\n",
    "class SelfEvaluation(BaseModel):\n",
    "    correctness: float = Field(ge=0.0, le=1.0)\n",
    "    performance_gain_estimate: float = Field(ge=0.0, le=1.0)\n",
    "    faithfulness: float = Field(ge=0.0, le=1.0)\n",
    "    comments: Optional[str] = None\n",
    "    results: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- Adaptive RAG Control ----------\n",
    "\n",
    "class RagStrategy(BaseModel):\n",
    "    retrievers_used: List[str]\n",
    "    retriever_weights: Dict[str, float]\n",
    "    rerank: bool = False\n",
    "    expanded_search: bool = False\n",
    "\n",
    "\n",
    "# ---------- Main LangGraph State ----------\n",
    "\n",
    "class QueryOptimizerState(BaseModel):\n",
    "    # Input\n",
    "    query: QueryMetadata\n",
    "\n",
    "    # Derived\n",
    "    slowness: Optional[SlownessScore] = None\n",
    "\n",
    "    # RAG\n",
    "    rag_context: List[RagDocument] = []\n",
    "    rag_strategy: RagStrategy = RagStrategy(\n",
    "        retrievers_used=[],\n",
    "        retriever_weights={}\n",
    "    )\n",
    "\n",
    "    # Optimization\n",
    "    optimization: Optional[OptimizationResult] = None\n",
    "\n",
    "    # Evaluation\n",
    "    self_eval: Optional[SelfEvaluation] = None\n",
    "\n",
    "    # Control flags\n",
    "    iteration: int = 0\n",
    "    max_iterations: int = 2\n",
    "    terminate: bool = False\n",
    "    context: List[Any] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc232",
   "metadata": {},
   "source": [
    "### This measures the slowness of the input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2835b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowness_score(state):\n",
    "    duration = (state.query.end_time - state.query.start_time).total_seconds()\n",
    "    # Simple heuristic: normalize duration to a score between 0 and 1\n",
    "    if duration < 1:\n",
    "        norm_score = 0.0\n",
    "    elif duration > 60:\n",
    "        norm_score = 1.0\n",
    "    else:\n",
    "        norm_score = duration / 60.0\n",
    "\n",
    "    reason = \"\"\n",
    "    if duration > 30:\n",
    "        reason = \"Query took longer than 30 seconds.\"\n",
    "    elif duration > 10:\n",
    "        reason = \"Query took longer than 10 seconds.\"\n",
    "        \n",
    "    print(\"--- CALCULATING SLOWNESS SCORE ---\")\n",
    "        \n",
    "    print(f\"Slowness duration: {duration} seconds, normalized score: {norm_score}, reason: {reason}\")\n",
    "        \n",
    "    slowness_score =  SlownessScore(\n",
    "        duration_seconds=duration,\n",
    "        normalized_score=norm_score,\n",
    "        reason=reason\n",
    "    )\n",
    "    state.slowness = slowness_score\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c012db",
   "metadata": {},
   "source": [
    "### Adaptive RAG Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9202d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(state):\n",
    "    query = state.query.statement_text\n",
    "    print(f\"Retrieving context for query: {query} and slowness score: {state.slowness.normalized_score}\")\n",
    "    score = state.slowness.normalized_score\n",
    "\n",
    "    retrievers = [\"anti_patterns\", \"spark\"]\n",
    "    if score > 0.6:\n",
    "        retrievers += [\"databricks\"]\n",
    "\n",
    "    context = []\n",
    "    for r in retrievers:\n",
    "        docs = load_retriever(r).invoke(query)\n",
    "        context.extend(docs)\n",
    "        \n",
    "    stats_doc = table_stats_retriever.invoke(query, k=2)\n",
    "    context.extend(stats_doc)\n",
    "    print(\"--- RETRIEVING CONTEXT DOCUMENTS ---\")\n",
    "    state.context = context\n",
    "    print(f\"Retrieved {len(context)} context documents.\")\n",
    "    # print(\"Top documents:\")\n",
    "    #for doc in context[:3]:   \n",
    "    #    print(f\"- {doc.page_content[:100]}... (source: {doc.metadata.get('source', 'unknown')})\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ecf1a",
   "metadata": {},
   "source": [
    "### Optimization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4a78f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import json\n",
    "\n",
    "def optimize_query(state):\n",
    "\n",
    "    llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Databricks SQL optimization expert.\\n\n",
    "    Query:\\n\n",
    "    {state.query.statement_text}\\n\n",
    "    Context:\\n\n",
    "    {state.context}\\n\\n\n",
    "    Tasks:\\n\n",
    "    1. Should this query be optimized?\\n\n",
    "    2. Rewrite query if needed\\n\n",
    "    3. Provide optimization suggestions\\n\n",
    "    Return JSON with keys: needs_optimization (bool), optimized_query (str or null), suggestions (list of str), applied_rules (list of str)\n",
    "    also provide the original query result as 'result' field.\n",
    "    \"\"\"\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    print(\"--- OPTIMIZATION STEP ---\")\n",
    "    #print(result.content)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    content = result.content.strip()\n",
    "    if content.startswith('```json'):\n",
    "        content = content[7:]  # Remove ```json\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3]  # Remove ```\n",
    "    content = content.strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        optimizationResult = OptimizationResult(**data)\n",
    "        optimizationResult.result = result.content\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        # Fallback\n",
    "        optimizationResult = OptimizationResult(\n",
    "            needs_optimization=True,\n",
    "            result=result.content,\n",
    "            optimized_query=None,\n",
    "            suggestions=[result.content],\n",
    "            applied_rules=[]\n",
    "        )\n",
    "\n",
    "    state.optimization = optimizationResult\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99805750",
   "metadata": {},
   "source": [
    "### Self Evaluation Agent\n",
    "### Based on the Optiization Agent it does the self Evaluation on the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "46cbde9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import json\n",
    "\n",
    "def self_evaluate(state):\n",
    "    llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "    eval_prompt = f\"\"\"\n",
    "       Evaluate the following optimization:\\n\n",
    "\n",
    "       {state.optimization.result}\\n\\n\n",
    "\n",
    "        Score from 0 to 1 for:\\n\n",
    "        - Correctness in float range 0.0 to 1.0 where 0.0 is incorrect and 1.0 is fully correct\\n\n",
    "        - Practical usefulness in float range 0.0 to 1.0 where 0.0 is not useful and 1.0 is very useful\\n\n",
    "        - performance_gain_estimate in float range 0.0 to 1.0 where 0.0 is no gain and 1.0 is significant gain\\n\n",
    "        - comments: any additional remarks\n",
    "\n",
    "        Return JSON with keys: correctness, practical_usefulness, performance_gain_estimate, comments\n",
    "        \"\"\"\n",
    "\n",
    "    response = llm.invoke(eval_prompt)\n",
    "    print(\"--- SELF-EVALUATION STEP ---\")\n",
    "   # print(response.content)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    content = response.content.strip()\n",
    "    if content.startswith('```json'):\n",
    "        content = content[7:]  # Remove ```json\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3]  # Remove ```\n",
    "    content = content.strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        self_eval = SelfEvaluation(\n",
    "            correctness=data.get(\"correctness\", 0.0),\n",
    "            faithfulness=data.get(\"practical_usefulness\", 0.0),  # Map practical_usefulness to faithfulness\n",
    "            performance_gain_estimate=data.get(\"performance_gain_estimate\", 0.0),\n",
    "            comments=data.get(\"comments\"),\n",
    "            results=response.content\n",
    "        )\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error in self_evaluate: {e}\")\n",
    "        # Fallback\n",
    "        self_eval = SelfEvaluation(\n",
    "            correctness=0.5,\n",
    "            faithfulness=0.5,\n",
    "            performance_gain_estimate=0.5,\n",
    "            comments=\"Parsing failed\",\n",
    "            results=response.content\n",
    "        )\n",
    "\n",
    "    state.self_eval = self_eval\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5814d",
   "metadata": {},
   "source": [
    "## Langraph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ad72d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "graph = StateGraph(QueryOptimizerState)\n",
    "\n",
    "graph.add_node(\"score\", slowness_score)\n",
    "graph.add_node(\"retrieve\", retrieve_context)\n",
    "graph.add_node(\"optimize\", optimize_query)\n",
    "graph.add_node(\"evaluate\", self_evaluate)\n",
    "\n",
    "# Build graph\n",
    "graph.add_edge(START, \"score\")\n",
    "graph.add_edge(\"score\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"optimize\")\n",
    "graph.add_edge(\"optimize\", \"evaluate\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fd0f6c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9cd66c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALCULATING SLOWNESS SCORE ---\n",
      "Slowness duration: 360.0 seconds, normalized score: 1.0, reason: Query took longer than 30 seconds.\n",
      "Retrieving context for query: SELECT * FROM orders WHERE amount > 1000 and slowness score: 1.0\n",
      "--- RETRIEVING CONTEXT DOCUMENTS ---\n",
      "Retrieved 14 context documents.\n",
      "--- OPTIMIZATION STEP ---\n",
      "--- SELF-EVALUATION STEP ---\n",
      "\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "SlownessScore : 1.0 and reason : Query took longer than 30 seconds. \n",
      "Optimization Needed : True\n",
      "Final Optimized Query : SELECT order_id, order_date, amount, customer_id\n",
      "FROM orders\n",
      "WHERE amount > 1000;\n",
      "Optimization Suggestions : ['Avoid SELECT * – list only the columns you actually need (column pruning).', 'If you frequently filter on `amount`, consider clustering the table on that column (e.g., Z‑ordering) to improve predicate push‑down.', 'Enable Adaptive Query Execution (AQE) in Databricks to let Spark dynamically choose the best join and shuffle strategies at runtime.', 'Make sure table statistics are up‑to‑date (`ANALYZE TABLE orders COMPUTE STATISTICS FOR COLUMNS amount;`). This helps the optimizer choose better plans.', 'If the query is part of a larger workflow that re‑uses the filtered result, cache the result set (`CACHE TABLE filtered_orders;`).', 'Consider adding a secondary index or a materialized view on `amount` if the workload is read‑heavy and the column is highly selective.', 'If the `orders` table is partitioned by `order_date`, add a date filter when possible to enable partition pruning.']\n",
      "Self Evaluation Correctness : 0.9\n",
      "Self Evaluation Correctness : The recommendations are generally sound: selecting only needed columns, keeping statistics up‑to‑date, and enabling AQE are standard best‑practices and will improve query planning and execution. The suggestion to cluster or index on `amount` may be overkill for a simple filter unless the table is very large and the predicate is highly selective. Caching is useful only if the filtered result is reused downstream. Overall the advice is correct and useful, but the expected performance gain for this specific query is modest—mainly from column pruning and better statistics rather than dramatic speed‑ups.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    # Example input\n",
    "    query_metadata = QueryMetadata(\n",
    "        user_name=\"alice\",\n",
    "        statement_text=\"SELECT * FROM orders WHERE amount > 1000\",\n",
    "        status=\"SUCCESS\",\n",
    "        start_time=datetime(2025,1,1,10,0,0),\n",
    "        end_time= datetime(2025,1,1,10,6,0)\n",
    "    )\n",
    "\n",
    "    initial_state = QueryOptimizerState(query=query_metadata)\n",
    "\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"\\n\\n=== FINAL OUTPUT ===\")\n",
    "    print(f\"SlownessScore : {final_state[\"slowness\"].normalized_score} and reason : {final_state[\"slowness\"].reason} \")\n",
    "    print(f\"Optimization Needed : {final_state[\"optimization\"].needs_optimization}\" )\n",
    "    print(f\"Final Optimized Query : {final_state[\"optimization\"].optimized_query}\" )\n",
    "    print(f\"Optimization Suggestions : {final_state[\"optimization\"].suggestions}\" ) \n",
    "    print(f\"Self Evaluation Correctness : {final_state[\"self_eval\"].correctness}\" )\n",
    "    print(f\"Self Evaluation Correctness : {final_state[\"self_eval\"].comments}\" )\n",
    "\n",
    "   # print(\"Final State:\")\n",
    "   # print(json.dumps(final_state, indent=2, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
