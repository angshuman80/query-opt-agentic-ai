{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba12624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"]= os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\", \"true\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\", \"https://api.langsmith.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cc319",
   "metadata": {},
   "source": [
    "### This step is Optional Just to show the LLM is working by making Groq Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965484af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bangs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'} template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'\n",
      "Question: What is the capital of France?\n",
      "Thought: The capital city of France is well‑known and can be answered directly from general knowledge.\n",
      "Final Answer: Paris.\n"
     ]
    }
   ],
   "source": [
    "## Install necessary packages and import modules\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "from langchain_classic.agents.react.agent import create_react_agent\n",
    "from langchain_classic import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "\n",
    "# Pull the react prompt from LangChain hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# Create the agent (with empty tools list)\n",
    "agent = prompt | llm | StrOutputParser()\n",
    "\n",
    "result = agent.invoke( {\"input\":\"What is the capital of France?\",\n",
    "                        \"tools\": [],\"agent_scratchpad\": \"\",\"tool_names\": []})\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7d002",
   "metadata": {},
   "source": [
    "## Buidling Retrievers for RAG to optimize the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ddcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Example usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "\n",
    "sources = {\n",
    "        \"anti_patterns\": \"playbook/SQL_anti_pattern.pdf\",\n",
    "        \"databricks\": \"playbook/Optimize_Databricks_Queries_overcast.pdf\",\n",
    "        \"spark\": \"playbook/spark_perf_tunning.pdf\"\n",
    "    }\n",
    "\n",
    "split_documents_list = []\n",
    "for source_name, pdf_path in sources.items():\n",
    "    # Example usage of PyPDFLoader\n",
    "    pdf_loader = PyPDFLoader(pdf_path)  # Replace with actual PDF path\n",
    "    pdf_documents = pdf_loader.load()\n",
    "    for d in pdf_documents:\n",
    "        d.metadata[\"source\"] = source_name\n",
    "\n",
    "    doc_splits = text_splitter.split_documents(pdf_documents)\n",
    "    split_documents_list.extend(doc_splits)\n",
    "    embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    Chroma.from_documents(\n",
    "            doc_splits,\n",
    "            embd,\n",
    "            persist_directory=f\"./chroma/{source_name}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5633be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JSON documents loaded: 2\n",
      "Number of documents in vectorstore: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Example usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
    "\n",
    "\n",
    "# Example usage of JSONLoader\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"stats/table_stats.json\",\n",
    "    jq_schema=\".[]\",\n",
    "    text_content=False)  # Replace with actual JSON path\n",
    "json_documents = json_loader.load()\n",
    "\n",
    "# Convert to new Documents with descriptive text\n",
    "new_documents = []\n",
    "for doc in json_documents:\n",
    "    data = json.loads(doc.page_content)\n",
    "    # Assuming JSON has keys: table_name, rows, partitioned_by\n",
    "    page_content = f\"Table {data.get('table', 'unknown')} has {data.get('row_count', 'unknown')} rows, partitioned by {data.get('partition_cols', 'unknown')} and size {data.get('size_mb', 'unknown')} mb.\"\n",
    "    metadata = {\"category\": \"table_stats\"}\n",
    "    new_doc = Document(page_content=page_content, metadata=metadata)\n",
    "    new_documents.append(new_doc)\n",
    "\n",
    "print(f\"Number of JSON documents loaded: {len(new_documents)}\")\n",
    "doc_splits = text_splitter.split_documents(new_documents)\n",
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# Add to vectorstore\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embd\n",
    ")\n",
    "\n",
    "print(f\"Number of documents in vectorstore: {vectorstore.index.ntotal}\")\n",
    "table_stats_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Example retrieval\n",
    "#query = \"provide table names ?\"\n",
    "#results = table_stats_retriever.invoke(query, k=2)\n",
    "#for i, doc in enumerate(results):\n",
    "#    print(f\"\\nDocument {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b75fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def load_retriever(name):\n",
    "    embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    db = Chroma(\n",
    "        persist_directory=f\"./chroma/{name}\",\n",
    "        embedding_function=embd\n",
    "    )\n",
    "    return db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Example usage\n",
    "#retriever = load_retriever(\"anti_patterns\")\n",
    "#retriever.invoke(\"What is select * anti-patterns?\")\n",
    "#!/usr/bin/env python3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112818b",
   "metadata": {},
   "source": [
    "## Tools and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18ecfb",
   "metadata": {},
   "source": [
    "### Defining Langraph State\n",
    "#### Using the Pydantic as the state class for the implicit validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30e4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bangs\\AppData\\Local\\Temp\\ipykernel_7716\\2548489269.py:16: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  @validator('start_time', 'end_time', pre=True)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Dict, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Core Input ----------\n",
    "# This will be captured from system.query_history of Databricks\n",
    "class QueryMetadata(BaseModel):\n",
    "    user_name: str\n",
    "    statement_text: str\n",
    "    status: str\n",
    "    start_time: datetime\n",
    "    end_time: datetime\n",
    "    warehouse_id: Optional[str] = None\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "    @validator('start_time', 'end_time', pre=True)\n",
    "    @classmethod\n",
    "    def parse_datetime(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return datetime.fromisoformat(v)\n",
    "        return v\n",
    "\n",
    "\n",
    "# ---------- RAG Document ----------\n",
    "\n",
    "class RagDocument(BaseModel):\n",
    "    content: str\n",
    "    source: str\n",
    "    score: Optional[float] = None\n",
    "\n",
    "\n",
    "# ---------- Slowness Scoring ----------\n",
    "\n",
    "class SlownessScore(BaseModel):\n",
    "    duration_seconds: float\n",
    "    normalized_score: float = Field(\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "        description=\"0 = fast, 1 = very slow\"\n",
    "    )\n",
    "    reason: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- Optimization Output ----------\n",
    "\n",
    "class OptimizationResult(BaseModel):\n",
    "    needs_optimization: bool\n",
    "    result: Optional[str] = None\n",
    "    optimized_query: Optional[str] = None\n",
    "    suggestions: List[str]\n",
    "    applied_rules: List[str]\n",
    "    result: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- Self Evaluation ----------\n",
    "\n",
    "class SelfEvaluation(BaseModel):\n",
    "    correctness: float = Field(ge=0.0, le=1.0)\n",
    "    performance_gain_estimate: float = Field(ge=0.0, le=1.0)\n",
    "    faithfulness: float = Field(ge=0.0, le=1.0)\n",
    "    comments: Optional[str] = None\n",
    "    results: Optional[str] = None\n",
    "\n",
    "\n",
    "# ---------- Adaptive RAG Control ----------\n",
    "\n",
    "class RagStrategy(BaseModel):\n",
    "    retrievers_used: List[str]\n",
    "    retriever_weights: Dict[str, float]\n",
    "    rerank: bool = False\n",
    "    expanded_search: bool = False\n",
    "\n",
    "\n",
    "# ---------- Main LangGraph State ----------\n",
    "\n",
    "class QueryOptimizerState(BaseModel):\n",
    "    # Input\n",
    "    query: QueryMetadata\n",
    "\n",
    "    # Derived\n",
    "    slowness: Optional[SlownessScore] = None\n",
    "\n",
    "    # RAG\n",
    "    rag_context: List[RagDocument] = []\n",
    "    rag_strategy: RagStrategy = RagStrategy(\n",
    "        retrievers_used=[],\n",
    "        retriever_weights={}\n",
    "    )\n",
    "\n",
    "    # Optimization\n",
    "    optimization: Optional[OptimizationResult] = None\n",
    "\n",
    "    # Evaluation\n",
    "    self_eval: Optional[SelfEvaluation] = None\n",
    "\n",
    "    # Control flags\n",
    "    iteration: int = 0\n",
    "    max_iterations: int = 2\n",
    "    terminate: bool = False\n",
    "    context: List[Any] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc232",
   "metadata": {},
   "source": [
    "### This measures the slowness of the input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2835b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowness_score(state):\n",
    "    duration = (state.query.end_time - state.query.start_time).total_seconds()\n",
    "    # Simple heuristic: normalize duration to a score between 0 and 1\n",
    "    if duration < 1:\n",
    "        norm_score = 0.0\n",
    "    elif duration > 60:\n",
    "        norm_score = 1.0\n",
    "    else:\n",
    "        norm_score = duration / 60.0\n",
    "\n",
    "    reason = \"\"\n",
    "    if duration > 30:\n",
    "        reason = \"Query took longer than 30 seconds.\"\n",
    "    elif duration > 10:\n",
    "        reason = \"Query took longer than 10 seconds.\"\n",
    "        \n",
    "    print(\"--- CALCULATING SLOWNESS SCORE ---\")\n",
    "        \n",
    "    print(f\"Slowness duration: {duration} seconds, normalized score: {norm_score}, reason: {reason}\")\n",
    "        \n",
    "    slowness_score =  SlownessScore(\n",
    "        duration_seconds=duration,\n",
    "        normalized_score=norm_score,\n",
    "        reason=reason\n",
    "    )\n",
    "    state.slowness = slowness_score\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c012db",
   "metadata": {},
   "source": [
    "### Adaptive RAG Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9202d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(state):\n",
    "    query = state.query.statement_text\n",
    "    print(f\"Retrieving context for query: {query} and slowness score: {state.slowness.normalized_score}\")\n",
    "    score = state.slowness.normalized_score\n",
    "\n",
    "    retrievers = [\"anti_patterns\", \"spark\"]\n",
    "    if score > 0.6:\n",
    "        retrievers += [\"databricks\"]\n",
    "\n",
    "    context = []\n",
    "    for r in retrievers:\n",
    "        docs = load_retriever(r).invoke(query)\n",
    "        context.extend(docs)\n",
    "        \n",
    "    stats_doc = table_stats_retriever.invoke(query, k=2)\n",
    "    print(f\"Retrieved stats documents: {stats_doc}\")\n",
    "    context.extend(stats_doc)\n",
    "    print(\"--- RETRIEVING CONTEXT DOCUMENTS ---\")\n",
    "    state.context = context\n",
    "    print(f\"Retrieved {len(context)} context documents.\")\n",
    "    # print(\"Top documents:\")\n",
    "    #for doc in context[:3]:   \n",
    "    #    print(f\"- {doc.page_content[:100]}... (source: {doc.metadata.get('source', 'unknown')})\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ecf1a",
   "metadata": {},
   "source": [
    "### Optimization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a78f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_classic.output_parsers import PydanticOutputParser\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "def optimize_query(state):\n",
    "\n",
    "    llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "    \n",
    "    parser = PydanticOutputParser(\n",
    "    pydantic_object=OptimizationResult)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a Databricks SQL optimization expert.\n",
    "\n",
    "    Query:\n",
    "    {query}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Tasks:\n",
    "    1. Decide whether this query should be optimized\n",
    "    2. Rewrite the query if needed\n",
    "    3. Provide optimization suggestions\n",
    "    4. List applied optimization rules\n",
    "    5. provide a summarized 'result' field containing -   Should this query be optimized? , Rewrite query if needed ,new query that is rewritten, and optimization suggestions\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "        input_variables=[\"query\", \"context\"],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        }\n",
    "    )\n",
    "    \n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"query\": state.query.statement_text,\n",
    "        \"context\": state.context\n",
    "    })\n",
    "    print(\"--- OPTIMIZATION STEP ---\")\n",
    "   # print(f\"Type of response: {type(response)} and content: {response} \")\n",
    "\n",
    "    state.optimization = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99805750",
   "metadata": {},
   "source": [
    "### Self Evaluation Agent\n",
    "### Based on the Optiization Agent it does the self Evaluation on the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46cbde9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import json\n",
    "from langchain_classic.output_parsers import PydanticOutputParser\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "def self_evaluate(state):\n",
    "    llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "    \n",
    "    parser = PydanticOutputParser(\n",
    "    pydantic_object=SelfEvaluation)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a Databricks SQL optimization expert.Evaluate the following optimization:\\n\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "        -  Score from 0 to 1 for:\\n\n",
    "        - Correctness in float range 0.0 to 1.0 where 0.0 is incorrect and 1.0 is fully correct\\n\n",
    "        - Practical usefulness in float range 0.0 to 1.0 where 0.0 is not useful and 1.0 is very useful\\n\n",
    "        - performance_gain_estimate in float range 0.0 to 1.0 where 0.0 is no gain and 1.0 is significant gain\\n\n",
    "        - comments: any additional remarks\n",
    "\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "        input_variables=[\"context\"],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        }\n",
    "    )\n",
    "  \n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"query\": state.query.statement_text,\n",
    "        \"context\": state.context\n",
    "    })\n",
    "    print(\"--- SELF-EVALUATION STEP ---\")\n",
    "\n",
    "    state.self_eval = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5814d",
   "metadata": {},
   "source": [
    "## Langraph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad72d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "graph = StateGraph(QueryOptimizerState)\n",
    "\n",
    "graph.add_node(\"score\", slowness_score)\n",
    "graph.add_node(\"retrieve\", retrieve_context)\n",
    "graph.add_node(\"optimize\", optimize_query)\n",
    "graph.add_node(\"evaluate\", self_evaluate)\n",
    "\n",
    "# Build graph\n",
    "graph.add_edge(START, \"score\")\n",
    "graph.add_edge(\"score\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"optimize\")\n",
    "graph.add_edge(\"optimize\", \"evaluate\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd0f6c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f74c9",
   "metadata": {},
   "source": [
    "### Invoking State Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cd66c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALCULATING SLOWNESS SCORE ---\n",
      "Slowness duration: 360.0 seconds, normalized score: 1.0, reason: Query took longer than 30 seconds.\n",
      "Retrieving context for query: SELECT * FROM orders WHERE amount > 1000 and slowness score: 1.0\n",
      "Retrieved stats documents: [Document(id='3a1e9954-69a1-4fe2-901b-fc427e36b219', metadata={'category': 'table_stats'}, page_content=\"Table orders has 120000000 rows, partitioned by ['order_date'] and size 48000 mb.\"), Document(id='0433fcd6-53a7-40f8-9c87-2376117f5360', metadata={'category': 'table_stats'}, page_content=\"Table customer has 120000 rows, partitioned by ['customer_id'] and size 4800 mb.\")]\n",
      "--- RETRIEVING CONTEXT DOCUMENTS ---\n",
      "Retrieved 14 context documents.\n",
      "--- OPTIMIZATION STEP ---\n",
      "--- SELF-EVALUATION STEP ---\n",
      "\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "final_state: {'query': QueryMetadata(user_name='alice', statement_text='SELECT * FROM orders WHERE amount > 1000', status='SUCCESS', start_time=datetime.datetime(2025, 1, 1, 10, 0), end_time=datetime.datetime(2025, 1, 1, 10, 6), warehouse_id=None, error_message=None), 'slowness': SlownessScore(duration_seconds=360.0, normalized_score=1.0, reason='Query took longer than 30 seconds.'), 'rag_context': [], 'rag_strategy': RagStrategy(retrievers_used=[], retriever_weights={}, rerank=False, expanded_search=False), 'optimization': OptimizationResult(needs_optimization=True, result='The query should be optimized. Rewrite it to select only required columns, e.g., SELECT order_id, amount, order_date FROM orders WHERE amount > 1000. Add partition filters if possible and consider Z‑ordering on the amount column for better pruning.', optimized_query='SELECT order_id, amount, order_date FROM orders WHERE amount > 1000', suggestions=['Avoid SELECT * – list only the columns you actually need (column pruning).', 'Add a filter on the partition column (order_date) to enable partition pruning.', \"Consider Z‑ordering the table on the 'amount' column if this filter is frequent (data skipping).\", 'Make sure table statistics are up‑to‑date so the optimizer can choose the best plan.', 'Use Delta Lake format and enable caching if the result set is reused in subsequent queries.'], applied_rules=['SELECT * anti‑pattern', 'Column pruning', 'Missing partition pruning', 'Data skipping / Z‑ordering recommendation', 'Statistics awareness']), 'self_eval': SelfEvaluation(correctness=0.88, performance_gain_estimate=0.62, faithfulness=0.85, comments=\"The suggested changes (avoiding SELECT *, applying partition pruning based on the provided table statistics, and using Spark/Databricks hints such as REPARTITION or REBALANCE where appropriate) are consistent with the anti‑pattern guidance and the hint examples in the supplied documents. They are technically correct and would reduce data scanned and shuffled, especially for the large 'orders' table (120\\u202fM rows, 48\\u202fGB). However, the actual gain depends on the query shape (joins, filters) and cluster configuration, so the estimate is moderate. The advice is practical for most workloads but may require tuning of hint parameters (e.g., number of partitions) to avoid over‑partitioning.\", results='Replace SELECT * with explicit column list, ensure filters on partition columns (order_date, customer_id) are present to enable partition pruning, and consider REPARTITION/REBALANCE hints on large shuffles. This should improve query latency and reduce compute cost.'), 'iteration': 0, 'max_iterations': 2, 'terminate': False, 'context': [Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'source': 'anti_patterns', 'creationdate': '', 'page': 0, 'total_pages': 6, 'title': 'SQL_anti_pattern', 'creator': 'PyPDF', 'page_label': '1'}, page_content='1.  SELECT  *  Anti-Pattern  \\nUsing  SELECT  *  in  your  SQL  queries  seems  convenient  but  can  lead  to  several  issues:  \\n●  Performance  Degradation:  Fetching  all  columns  can  slow  down  your  queries,  \\nespecially\\n \\nwhen\\n \\ndealing\\n \\nwith\\n \\nlarge\\n \\ndatasets.\\n ●  Excessive  Data  Transfer:  Returning  more  data  than  necessary  increases  load  on  \\nthe\\n \\nnetwork\\n \\nand\\n \\nthe\\n \\nclient\\n \\napplication.'), Document(metadata={'creationdate': '', 'page': 0, 'title': 'SQL_anti_pattern', 'page_label': '1', 'total_pages': 6, 'creator': 'PyPDF', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'source': 'anti_patterns'}, page_content='1.  SELECT  *  Anti-Pattern  \\nUsing  SELECT  *  in  your  SQL  queries  seems  convenient  but  can  lead  to  several  issues:  \\n●  Performance  Degradation:  Fetching  all  columns  can  slow  down  your  queries,  \\nespecially\\n \\nwhen\\n \\ndealing\\n \\nwith\\n \\nlarge\\n \\ndatasets.\\n ●  Excessive  Data  Transfer:  Returning  more  data  than  necessary  increases  load  on  \\nthe\\n \\nnetwork\\n \\nand\\n \\nthe\\n \\nclient\\n \\napplication.'), Document(metadata={'creationdate': '', 'page': 0, 'title': 'SQL_anti_pattern', 'source': 'anti_patterns', 'total_pages': 6, 'creator': 'PyPDF', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'page_label': '1'}, page_content='1.  SELECT  *  Anti-Pattern  \\nUsing  SELECT  *  in  your  SQL  queries  seems  convenient  but  can  lead  to  several  issues:  \\n●  Performance  Degradation:  Fetching  all  columns  can  slow  down  your  queries,  \\nespecially\\n \\nwhen\\n \\ndealing\\n \\nwith\\n \\nlarge\\n \\ndatasets.\\n ●  Excessive  Data  Transfer:  Returning  more  data  than  necessary  increases  load  on  \\nthe\\n \\nnetwork\\n \\nand\\n \\nthe\\n \\nclient\\n \\napplication.'), Document(metadata={'creator': 'PyPDF', 'creationdate': '', 'page': 0, 'producer': 'Skia/PDF m145 Google Docs Renderer', 'title': 'SQL_anti_pattern', 'source': 'anti_patterns', 'total_pages': 6, 'page_label': '1'}, page_content='1.  SELECT  *  Anti-Pattern  \\nUsing  SELECT  *  in  your  SQL  queries  seems  convenient  but  can  lead  to  several  issues:  \\n●  Performance  Degradation:  Fetching  all  columns  can  slow  down  your  queries,  \\nespecially\\n \\nwhen\\n \\ndealing\\n \\nwith\\n \\nlarge\\n \\ndatasets.\\n ●  Excessive  Data  Transfer:  Returning  more  data  than  necessary  increases  load  on  \\nthe\\n \\nnetwork\\n \\nand\\n \\nthe\\n \\nclient\\n \\napplication.'), Document(metadata={'total_pages': 15, 'source': 'spark', 'page_label': '4', 'title': 'Spark_perf_tunning', 'page': 3, 'creator': 'PyPDF', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'creationdate': ''}, page_content='as\\n \\nparameters.\\n \\nSELECT /*+  COALESCE(3)  */ * FROM t;  SELECT /*+  REPARTITION(3)  */ * FROM t;  SELECT /*+  REPARTITION(c)  */ * FROM t;  SELECT /*+  REPARTITION(3,  c)  */ * FROM t;  SELECT /*+  REPARTITION  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(c)  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(3,  c)  */ * FROM t;  SELECT /*+  REBALANCE  */ * FROM t;  SELECT /*+  REBALANCE(3)  */ * FROM t;  SELECT /*+  REBALANCE(c)  */ * FROM t;  SELECT /*+  REBALANCE(3,  c)  */ * FROM t;'), Document(metadata={'total_pages': 15, 'page': 3, 'creator': 'PyPDF', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'source': 'spark', 'creationdate': '', 'title': 'Spark_perf_tunning', 'page_label': '4'}, page_content='as\\n \\nparameters.\\n \\nSELECT /*+  COALESCE(3)  */ * FROM t;  SELECT /*+  REPARTITION(3)  */ * FROM t;  SELECT /*+  REPARTITION(c)  */ * FROM t;  SELECT /*+  REPARTITION(3,  c)  */ * FROM t;  SELECT /*+  REPARTITION  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(c)  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(3,  c)  */ * FROM t;  SELECT /*+  REBALANCE  */ * FROM t;  SELECT /*+  REBALANCE(3)  */ * FROM t;  SELECT /*+  REBALANCE(c)  */ * FROM t;  SELECT /*+  REBALANCE(3,  c)  */ * FROM t;'), Document(metadata={'creationdate': '', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'page': 3, 'total_pages': 15, 'creator': 'PyPDF', 'title': 'Spark_perf_tunning', 'page_label': '4', 'source': 'spark'}, page_content='as\\n \\nparameters.\\n \\nSELECT /*+  COALESCE(3)  */ * FROM t;  SELECT /*+  REPARTITION(3)  */ * FROM t;  SELECT /*+  REPARTITION(c)  */ * FROM t;  SELECT /*+  REPARTITION(3,  c)  */ * FROM t;  SELECT /*+  REPARTITION  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(c)  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(3,  c)  */ * FROM t;  SELECT /*+  REBALANCE  */ * FROM t;  SELECT /*+  REBALANCE(3)  */ * FROM t;  SELECT /*+  REBALANCE(c)  */ * FROM t;  SELECT /*+  REBALANCE(3,  c)  */ * FROM t;'), Document(metadata={'creator': 'PyPDF', 'page': 3, 'creationdate': '', 'producer': 'Skia/PDF m145 Google Docs Renderer', 'page_label': '4', 'title': 'Spark_perf_tunning', 'total_pages': 15, 'source': 'spark'}, page_content='as\\n \\nparameters.\\n \\nSELECT /*+  COALESCE(3)  */ * FROM t;  SELECT /*+  REPARTITION(3)  */ * FROM t;  SELECT /*+  REPARTITION(c)  */ * FROM t;  SELECT /*+  REPARTITION(3,  c)  */ * FROM t;  SELECT /*+  REPARTITION  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(c)  */ * FROM t;  SELECT /*+  REPARTITION_BY_RANGE(3,  c)  */ * FROM t;  SELECT /*+  REBALANCE  */ * FROM t;  SELECT /*+  REBALANCE(3)  */ * FROM t;  SELECT /*+  REBALANCE(c)  */ * FROM t;  SELECT /*+  REBALANCE(3,  c)  */ * FROM t;'), Document(metadata={'source': 'databricks', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0', 'page': 1, 'total_pages': 36, 'moddate': '2025-12-28T07:35:58+00:00', 'page_label': '2', 'title': '13 Ways to Optimize Databricks Queries | overcast blog', 'producer': 'Skia/PDF m143', 'creationdate': '2025-12-28T07:35:58+00:00'}, page_content='consumption, leading to lower operational costs. Additionally, well-\\noptimized queries improve the overall user experience by providing faster\\nresponse times, which is particularly important in interactive data analytics\\nenvironments.\\nWhen to Use Query Optimization Techniques\\nQuery optimization should be an ongoing process, especially in\\nenvironments where data volumes and workloads fluctuate. It is particularly\\nimportant during the development and deployment of new data pipelines, as'), Document(metadata={'source': 'databricks', 'page_label': '2', 'creationdate': '2025-12-28T07:35:58+00:00', 'title': '13 Ways to Optimize Databricks Queries | overcast blog', 'total_pages': 36, 'producer': 'Skia/PDF m143', 'moddate': '2025-12-28T07:35:58+00:00', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0', 'page': 1}, page_content='consumption, leading to lower operational costs. Additionally, well-\\noptimized queries improve the overall user experience by providing faster\\nresponse times, which is particularly important in interactive data analytics\\nenvironments.\\nWhen to Use Query Optimization Techniques\\nQuery optimization should be an ongoing process, especially in\\nenvironments where data volumes and workloads fluctuate. It is particularly\\nimportant during the development and deployment of new data pipelines, as'), Document(metadata={'page': 1, 'moddate': '2025-12-28T07:35:58+00:00', 'title': '13 Ways to Optimize Databricks Queries | overcast blog', 'total_pages': 36, 'page_label': '2', 'creationdate': '2025-12-28T07:35:58+00:00', 'producer': 'Skia/PDF m143', 'source': 'databricks', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0'}, page_content='consumption, leading to lower operational costs. Additionally, well-\\noptimized queries improve the overall user experience by providing faster\\nresponse times, which is particularly important in interactive data analytics\\nenvironments.\\nWhen to Use Query Optimization Techniques\\nQuery optimization should be an ongoing process, especially in\\nenvironments where data volumes and workloads fluctuate. It is particularly\\nimportant during the development and deployment of new data pipelines, as'), Document(metadata={'page_label': '2', 'source': 'databricks', 'total_pages': 36, 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0', 'title': '13 Ways to Optimize Databricks Queries | overcast blog', 'moddate': '2025-12-28T07:35:58+00:00', 'creationdate': '2025-12-28T07:35:58+00:00', 'producer': 'Skia/PDF m143', 'page': 1}, page_content='consumption, leading to lower operational costs. Additionally, well-\\noptimized queries improve the overall user experience by providing faster\\nresponse times, which is particularly important in interactive data analytics\\nenvironments.\\nWhen to Use Query Optimization Techniques\\nQuery optimization should be an ongoing process, especially in\\nenvironments where data volumes and workloads fluctuate. It is particularly\\nimportant during the development and deployment of new data pipelines, as'), Document(id='3a1e9954-69a1-4fe2-901b-fc427e36b219', metadata={'category': 'table_stats'}, page_content=\"Table orders has 120000000 rows, partitioned by ['order_date'] and size 48000 mb.\"), Document(id='0433fcd6-53a7-40f8-9c87-2376117f5360', metadata={'category': 'table_stats'}, page_content=\"Table customer has 120000 rows, partitioned by ['customer_id'] and size 4800 mb.\")]}\n",
      "SlownessScore : 1.0 and reason : Query took longer than 30 seconds. \n",
      "Optimization Needed : True\n",
      "Final Optimized Query : SELECT order_id, amount, order_date FROM orders WHERE amount > 1000\n",
      "Optimization Suggestions : ['Avoid SELECT * – list only the columns you actually need (column pruning).', 'Add a filter on the partition column (order_date) to enable partition pruning.', \"Consider Z‑ordering the table on the 'amount' column if this filter is frequent (data skipping).\", 'Make sure table statistics are up‑to‑date so the optimizer can choose the best plan.', 'Use Delta Lake format and enable caching if the result set is reused in subsequent queries.']\n",
      "Self Evaluation Correctness : 0.88\n",
      "Self Evaluation final comments : The suggested changes (avoiding SELECT *, applying partition pruning based on the provided table statistics, and using Spark/Databricks hints such as REPARTITION or REBALANCE where appropriate) are consistent with the anti‑pattern guidance and the hint examples in the supplied documents. They are technically correct and would reduce data scanned and shuffled, especially for the large 'orders' table (120 M rows, 48 GB). However, the actual gain depends on the query shape (joins, filters) and cluster configuration, so the estimate is moderate. The advice is practical for most workloads but may require tuning of hint parameters (e.g., number of partitions) to avoid over‑partitioning.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    # Example input as dict (can be loaded from JSON)\n",
    "    initial_state = {\n",
    "        \"query\": {\n",
    "            \"user_name\": \"alice\",\n",
    "            \"statement_text\": \"SELECT * FROM orders WHERE amount > 1000\",\n",
    "            \"status\": \"SUCCESS\",\n",
    "            \"start_time\": \"2025-01-01T10:00:00\",\n",
    "            \"end_time\": \"2025-01-01T10:06:00\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\\n=== FINAL OUTPUT ===\")\n",
    "    print(f\"final_state: {final_state}\")\n",
    "    print(f\"SlownessScore : {final_state['slowness'].normalized_score} and reason : {final_state['slowness'].reason} \")\n",
    "    print(f\"Optimization Needed : {final_state[\"optimization\"].needs_optimization}\" )\n",
    "    print(f\"Final Optimized Query : {final_state[\"optimization\"].optimized_query}\" )\n",
    "    print(f\"Optimization Suggestions : {final_state[\"optimization\"].suggestions}\" ) \n",
    "    print(f\"Self Evaluation Correctness : {final_state[\"self_eval\"].correctness}\" )\n",
    "    print(f\"Self Evaluation final comments : {final_state[\"self_eval\"].comments}\" )\n",
    "\n",
    "   # print(\"Final State:\")\n",
    "   # print(json.dumps(final_state, indent=2, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
